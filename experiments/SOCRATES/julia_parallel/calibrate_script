#!/bin/bash

#Submit this script with: sbatch calibrate_script

#SBATCH --time=09:00:00   # walltime, longer, calibration with all keeps failing...
#SBATCH --ntasks=11  # number of processor cores (i.e. tasks) (each node I believe on HPC has 64 cpus as per sinfo --Node --long | head -n 10) | ran out of time on like iteration 6-8... (currently running 15 ensemble members x 6 cases per ensemble member...)
#SBATCH --nodes=1   # number of nodes, a range works i suppose, before i went 1-ntasks but that crashed maybe too many things open? idk...
#SBATCH -J "ekp_socrates"   # job name
#SBATCH --mem-per-cpu=60G   # memory per CPU core (one job failed runining 6 cases with 6G, trying again w/ 10G... failed w/ 10, trying w/ 20)
#SBATCH --output=slurm_julia_par_%j.out

module purge

config=${1?Error: no config file given} # maybe we add later to just default to config.jl in the experiment directory?
# check if script is started via SLURM or bash (https://stackoverflow.com/q/56962129/13331585) | if with SLURM: there variable '$SLURM_JOB_ID' will exist `if [ -n $SLURM_JOB_ID ]` checks if $SLURM_JOB_ID is not an empty string

# if false;  then # need to add quotes here, see https://unix.stackexchange.com/questions/109625/shell-scripting-z-and-n-options-with-if#comment1152278_109631
# if [ -n "$SLURM_JOB_ID" ];  then # need to add quotes here, see https://unix.stackexchange.com/questions/109625/shell-scripting-z-and-n-options-with-if#comment1152278_109631 | seems to crash on HPC even when launched form slurm... idk why... works on clima... just says  command is sh

#     # check the original location through scontrol and $SLURM_JOB_ID
#     thisfile=$(scontrol show job $SLURM_JOBID | awk -F= '/Command=/{print $2}')
# else # otherwise: started with bash. Get the real location.
#     # thisfile=$(realpath $0)
#     thisfile="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/$(basename "${BASH_SOURCE[0]}")" # the location of this file I think is more versatile than the stack overflow solution (see https://stackoverflow.com/a/9107028/13331585), realpath might be better though idk...
# fi

# scriptDir="$(dirname $0)" # works w/ no slurm but already on interactive noe
# echo $scriptDir
# scriptDir=$(scontrol show job $SLURM_JOBID | awk -F= '/Command=/{print $2}') # works w/ slurm both while and while not on interactive node?
# echo $scriptDir
# scriptDir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/$(basename "${BASH_SOURCE[0]}")" # the location of this file I think is more versatile than the stack overflow solution (see https://stackoverflow.com/a/9107028/13331585), realpath might be better though idk...
# echo $scriptDir


thisfile=/home/jbenjami/Research_Schneider/CliMa/CalibrateEDMF.jl/experiments/SOCRATES/julia_parallel/calibrate_script # can't figure out how to fool proof make this work w/ HPC even on interactive node which has a separate slurm id... this makes it however, not at all transporatable to other machines...
thisdir=$(dirname $thisfile) # go up to directory from filename...
experiment_dir=$(dirname $thisdir) # go up to experiment directory...
log_dir=${experiment_dir}/Output/Logs/

echo $thisfile




use_expansion=false



if $(grep -q "Red Hat" /etc/redhat-release);  then # copied from /groups/esm/slurm-buildkite/hooks/environment
    os_type="rhel9" # "We are on a RedHat 9 node"
else 
	os_type="centos7" # some of the expansion nodes still seem to be running centos7 for some strange reason? idk...
fi

if [ "$use_expansion" = false ] || [ "$os_type" = "centos7" ]; then # use_expansion is false or os_type is centos7 despite being on expansion node (idk why that is happening lol)
    # module load julia/1.9.3 openmpi/4.1.5 # do we need open mpi?
    module purge
    module load julia/1.10.0 mpich/4.0.0 # copied from other experiments
else
    # cat /etc/os-release # just to be sure
    source /etc/profile.d/modules.sh # # module seems to not be defined when we call this on expansion? idk why... hopefully this does it automatically, see https://climate-machine.slack.com/archives/CKH8UUZHR/p1700178461357699?thread_ts=1700174744.568459&cid=CKH8UUZHR 
    # Try running on expansion cores
    module purge
    export MODULEPATH="/groups/esm/modules:$MODULEPATH" # see https://github.com/CliMA/ClimaModules, provides julia, julia-preferences, mpiwrapper
    export MODULEPATH="/central/software9/Modules/linux-rhel9-x86_64:/central/software9/Modules/linux-rhel9-broadwell:/central/software9/Modules/linux-rhel9-skylake_avx512:/central/software9/Modules/external/modulefiles:$MODULEPATH" # for some reason these aren't getting loaded ... idk why... it's some weird mix of expansion and regular modules  but only the regular centos7 are getting loaded by sbatch idk but not the rhel9 ones..., plus /central/software9/Modules/external/modulefiles for nsight_systems for climacommon
    # # module load climacommon
    # module load climacommon/2024_10_08 # avoid julia 1.11 for now # doesnt work bc of nsys
    # module load julia/1.10.1 
    # module load julia-preferences/2024_02_20
    # module load mpiwrapper/2024_02_27 # is this all we need for mpi? the code still complained about libmpi not being found but it still ran? idk...
    # module load climacommon
    module load climacommon/2024_10_08 # avoid julia 1.11 for now
fi


# julia -e 'using Pkg; using MPIPreferences; use_system_binary()' # the new way to do this, see ` Warning: The JULIA_MPI_BINARY environment variable is no longer used to configure the MPI binary. Use MPIPreferences.use_system_binary() instead.`

julia --project -e 'using Pkg; Pkg.instantiate(); Pkg.API.precompile()'

julia --project -p 11 ${thisdir}/calibrate.jl --config $config # Not sure how many processors I should go for... maybe at least 1 more than the batch size?
